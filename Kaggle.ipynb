{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6-Kaggle.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WRff5x-3TYI"
      },
      "source": [
        "# This cell is necessary only if you are running on Google Colab. It downloads the files to your\n",
        "# Colab instance so you don't have to upload them here.\n",
        "\n",
        "import requests\n",
        "\n",
        "def save_file(url, file_name):\n",
        "    r = requests.get(url)\n",
        "    with open(file_name, 'wb') as f:\n",
        "      f.write(r.content)\n",
        "\n",
        "save_file('https://courses.cs.washington.edu/courses/cse416/21sp/homework/hw6/edx_train.csv', \n",
        "          'edx_train.csv')\n",
        "save_file('https://courses.cs.washington.edu/courses/cse416/21sp/homework/hw6/edx_test.csv', \n",
        "          'edx_test.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8I5K5PO4M-u",
        "outputId": "a9ca609b-b8b5-418a-c25f-fe89d375b6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# original features and target\n",
        "features = ['viewed', \n",
        "            'explored', \n",
        "            'grade', \n",
        "            'nevents', \n",
        "            'ndays_act', \n",
        "            'nplay_video',\n",
        "            'nchapters', \n",
        "            'nforum_posts']\n",
        "target = ['certified']\n",
        "\n",
        "# load train and test data\n",
        "train_data = pd.read_csv('edx_train.csv', na_values=' ')\n",
        "train_data = train_data.fillna(0)\n",
        "\n",
        "test_data = pd.read_csv('edx_test.csv', na_values=' ')\n",
        "test_data = test_data.fillna(0)\n",
        "\n",
        "\n",
        "# classifier 1: DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# translate the categorical features into numeric ones\n",
        "train_data_dtc = pd.get_dummies(train_data[features + target])\n",
        "test_data_dtc = pd.get_dummies(test_data[features])\n",
        "\n",
        "# prepare the features and target for the model\n",
        "features_dtc = list(train_data_dtc.columns)\n",
        "features_dtc.remove('certified')\n",
        "\n",
        "# train and predict\n",
        "decision_tree_model = DecisionTreeClassifier(max_depth=6, random_state=6)\n",
        "decision_tree_model.fit(train_data_dtc[features_dtc], train_data_dtc[target])\n",
        "\n",
        "predictions_decisiontree = decision_tree_model.predict(test_data_dtc[features_dtc])\n",
        "\n",
        "# save prediction result\n",
        "to_save = test_data[['userid_DI']].copy()\n",
        "to_save.loc[:, 'certified'] = predictions_decisiontree\n",
        "to_save.to_csv('submission_decisiontree.csv', index=False)\n",
        "\n",
        "\n",
        "# classifier 2: LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# train and predict\n",
        "logitic_regression_model = LogisticRegression(penalty='l2', random_state=1, C=1e23)\n",
        "logitic_regression_model.fit(train_data[features], train_data[target])\n",
        "\n",
        "predictions_logistic = logitic_regression_model.predict(test_data[features])\n",
        "\n",
        "# save prediction result\n",
        "to_save = test_data[['userid_DI']].copy()\n",
        "to_save.loc[:, 'certified'] = predictions_logistic\n",
        "to_save.to_csv('submission_logistic.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "# classifier 3: AdaBoostClassifier\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# train and predict\n",
        "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
        "abc.fit(train_data[features], train_data[target])\n",
        "\n",
        "predictions_abc = abc.predict(test_data[features])\n",
        "\n",
        "# save prediction result\n",
        "to_save = test_data[['userid_DI']].copy()\n",
        "to_save.loc[:, 'certified'] = predictions_abc\n",
        "to_save.to_csv('submission_abc.csv', index=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntbw8h3RIvq1"
      },
      "source": [
        "##### CSE 416\n",
        "##### Homework 6\n",
        "##### Xiaoxi Xia\n",
        "##### Name on the Kaggle: Watermelon\n",
        "\n",
        "#### Report:\n",
        " \n",
        "##### I use \"viewed, explored, grade, nevents, ndays_act, nplay_video, nchapters, nforum_posts\" as features. they seem important for final model. Something like \"gender, event_data\" I do not pick. I translate the features into numeric ones.\n",
        "##### For improving my prediction, I drop the missing data. except Decision tree, Adaboost, and Logistic, I tried to use linear and LASSO, but them have problem of float type. Decision tree, Adaboost, and Logistic are more effective.\n",
        "             \n",
        "             \n",
        "             \n",
        "            \n",
        "            \n",
        "            \n",
        "\n",
        "\n"
      ]
    }
  ]
}